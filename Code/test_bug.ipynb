{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/.DS_Store\n",
      "/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/down_up\n",
      "/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/up\n",
      "/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/down\n",
      "First 10 labels indices:  [0, 2, 1, 0, 1]\n",
      "layer nums: 178\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class '__main__.DataGenerator'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9289f70ce2a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_batch_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                    callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    531\u001b[0m                      'at same time.')\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m   \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m   \u001b[0;31m# Handle validation_split, we want to split the data and get the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 998\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    999\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class '__main__.DataGenerator'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import pathlib\n",
    "\n",
    "data_root = pathlib.Path.home().joinpath('Documents/Unimelb/Dissertation/test_Data/train_img/')\n",
    "for item in data_root.iterdir():\n",
    "  print(item)\n",
    "import random\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "image_count = len(all_image_paths)\n",
    "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "all_image_labels =[]\n",
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                    for path in all_image_paths]\n",
    "\n",
    "print(\"First 10 labels indices: \", all_image_labels[:5])\n",
    "import numpy as np\n",
    "# np.save('all_image_paths.npy', all_image_paths)\n",
    "all_image_paths = np.asarray(all_image_paths)\n",
    "\n",
    "# One hot vector representation of labels\n",
    "all_image_labels = np.asarray(all_image_labels)\n",
    "from keras.utils import to_categorical, Sequence\n",
    "all_image_labels = to_categorical(all_image_labels, num_classes=3)\n",
    "\n",
    "# saving the y_labels_one_hot array as a .npy file\n",
    "# np.save('all_image_labels.npy', all_image_labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(all_image_paths, all_image_labels, test_size=0.2, random_state=6)\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import keras\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence) :\n",
    "    def __init__(self, image_filenames, labels,\n",
    "                 batch_size, img_size=(224,224), *args, **kwargs):\n",
    "        self.image_filenames = image_filenames\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (np.ceil(len(self.image_filenames)/\n",
    "                        float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    \n",
    "    def __data_generation(self, file_paths, labels):\n",
    "        X = np.empty((self.batch_size, *self.img_size, 1))\n",
    "        Y = np.empty((self.batch_size, 3), dtype=np.float32)\n",
    "        for i, ID in enumerate(file_paths):\n",
    "            X[i,] = imread(ID)\n",
    "        for i, _ in enumerate(labels):\n",
    "            Y[i,] = labels[i]\n",
    "        return X, Y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx*self.batch_size:\n",
    "                                       (idx+1)*self.batch_size]\n",
    "        batch_y = self.labels[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        \n",
    "        x, y = self.__data_generation(batch_x, batch_y)\n",
    "#         np.array([resize(imread(file_name), (224, 224, 3))\n",
    "#                for file_name in batch_x])/255.0, np.array(batch_y)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "training_batch_generator = DataGenerator(x_train, y_train, batch_size)\n",
    "validation_batch_generator = DataGenerator(x_val, y_val, batch_size)  \n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# base_model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "# base_model = VGG19(include_top=False, input_shape=(224, 224, 3))\n",
    "# base_model = MobileNet(include_top=False, input_shape=(224, 224, 3))\n",
    "base_model = ResNet50(include_top=False, input_shape=(224, 224, 3))\n",
    "# base_model = InceptionV3(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "    \n",
    "FC_NUMS = 1024\n",
    "IMAGE_SIZE = 224\n",
    "FREEZE_LAYERS = 160\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(FC_NUMS, activation='relu')(x)\n",
    "prediction = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 构造完新的FC层，加入custom层\n",
    "model = Model(inputs=base_model.input, outputs=prediction)\n",
    "# 可观察模型结构\n",
    "# model.summary()\n",
    "# 获取模型的层数\n",
    "print(\"layer nums:\", len(model.layers))\n",
    "\n",
    "for layer in model.layers[:FREEZE_LAYERS]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[FREEZE_LAYERS:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "learing_rate = 1e-3\n",
    "model.compile(optimizer=SGD(lr=learing_rate),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "epochs = 20\n",
    "def scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
    "    \n",
    "callbacks = [\n",
    "# 当验证集上的损失“val_loss”连续两个训练回合（epoch）都没有变化，则提前结束训练\n",
    "tf.keras.callbacks.EarlyStopping(patience=4, monitor='val_loss'),\n",
    "# 使用TensorBoard保存训练的记录，保存到“./logs”目录中\n",
    "tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "tf.keras.callbacks.LearningRateScheduler(scheduler)]\n",
    "\n",
    "history = model.fit(training_batch_generator,\n",
    "                    steps_per_epoch=len(x_train) // batch_size,\n",
    "                    epochs=epochs, verbose=1,\n",
    "                    validation_data = validation_batch_generator,\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitc3aff01e4887446cafe7684cf3736cfd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
