{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitc3aff01e4887446cafe7684cf3736cfd",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "/Users/cyril/Documents/Github/Dissertation/Data/Triple Tops\n/Users/cyril/Documents/Github/Dissertation/Data/.DS_Store\n/Users/cyril/Documents/Github/Dissertation/Data/Pipe Tops\n/Users/cyril/Documents/Github/Dissertation/Data/Flags\n/Users/cyril/Documents/Github/Dissertation/Data/Rectangle Tops\n/Users/cyril/Documents/Github/Dissertation/Data/Gaps\n/Users/cyril/Documents/Github/Dissertation/Data/Island Reversals\n/Users/cyril/Documents/Github/Dissertation/Data/Horn Bottoms\n/Users/cyril/Documents/Github/Dissertation/Data/Scallops\n/Users/cyril/Documents/Github/Dissertation/Data/Pipe Bottoms\n/Users/cyril/Documents/Github/Dissertation/Data/Horn Tops\n/Users/cyril/Documents/Github/Dissertation/Data/Pennants\n/Users/cyril/Documents/Github/Dissertation/Data/Triple Bottoms\n/Users/cyril/Documents/Github/Dissertation/Data/Rectangle Bottoms\nFirst 10 labels indices:  [5, 12, 1, 5, 1, 8, 5, 7, 1, 10]\n"
    }
   ],
   "source": [
    "\n",
    "data_root = pathlib.Path.home().joinpath('Documents/Github/Dissertation/Data/')\n",
    "for item in data_root.iterdir():\n",
    "   print(item)\n",
    "\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths if \"DS_Store\" not in str(path)]\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "image_count = len(all_image_paths)\n",
    "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "all_image_labels = []\n",
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                   for path in all_image_paths]\n",
    "\n",
    "print(\"First 10 labels indices: \", all_image_labels[:10])\n",
    "\n",
    "img_size = (224, 224)\n",
    "def load_and_preprocess_image(image):\n",
    "   image = cv2.imread(image)\n",
    "   image = cv2.resize(image, img_size)\n",
    "   image = image[:, :, [2, 1, 0]]\n",
    "   image = image.astype('float64')\n",
    "   image /= 255.0  # normalize to [0,1] range\n",
    "\n",
    "   return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, img in enumerate(all_image_paths):\n",
    "    f = open(img.split('.')[0]+'.txt', 'a')\n",
    "    content = str(all_image_labels[i]) + \" 0.0 0.0 1.0 1.0\"\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "# Current directory\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "print(current_dir)\n",
    "current_dir = 'Data/'\n",
    "# Percentage of images to be used for the test set\n",
    "percentage_test = 20\n",
    "# Create and/or truncate train.txt and test.txt\n",
    "file_train = open('train.txt', 'w')  \n",
    "file_test = open('test.txt', 'w')\n",
    "# Populate train.txt and test.txt\n",
    "counter = 1  \n",
    "index_test = round(100 / percentage_test)  \n",
    "for pathAndFilename in glob.iglob(os.path.join(current_dir, \"*.jpg\")):  \n",
    "    title, ext = os.path.splitext(os.path.basename(pathAndFilename))\n",
    "if counter == index_test:\n",
    "        counter = 1\n",
    "        file_test.write(current_dir + \"/\" + title + '.jpg' + \"\\n\")\n",
    "    else:\n",
    "        file_train.write(current_dir + \"/\" + title + '.jpg' + \"\\n\")\n",
    "        counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "features {\n  feature {\n    key: \"depth\"\n    value {\n      int64_list {\n        value: 3\n      }\n    }\n  }\n  feature {\n    key: \"height\"\n    value {\n      int64_list {\n        value: 307\n      }\n...\n"
    }
   ],
   "source": [
    "\n",
    "image_string = open(all_image_paths[0], 'rb').read()\n",
    "label = all_image_labels[0]\n",
    "\n",
    "def image_example(image_string, label):\n",
    "    image_shape = tf.image.decode_jpeg(image_string).shape\n",
    "\n",
    "    feature = {\n",
    "        'height': _int64_feature(image_shape[0]),\n",
    "        'width': _int64_feature(image_shape[1]),\n",
    "        'depth': _int64_feature(image_shape[2]),\n",
    "        'label': _int64_feature(label),\n",
    "        'image_raw': _bytes_feature(image_string),}\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \n",
    "for line in str(image_example(image_string, label)).split('\\n')[:15]:\n",
    "    print(line)\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'list'>\n<class 'list'>\n<class 'list'>\n<class 'list'>\n"
    }
   ],
   "source": [
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(all_image_paths, all_image_labels, test_size=0.1, random_state=3)\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(y_train))\n",
    "print(type(X_val))\n",
    "print(type(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in X_train:\n",
    "    f = open('train.txt', 'a')\n",
    "    f.write(name)\n",
    "    f.write('\\n')\n",
    "for name in X_val:\n",
    "    f = open('test.txt', 'a')\n",
    "    f.write(name)\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train_images.tfrecords'\n",
    "with tf.io.TFRecordWriter(train_file) as writer:\n",
    "    for i, filename in enumerate(X_train):\n",
    "        image_string = open(filename, 'rb').read()\n",
    "        tf_example = image_example(image_string, y_train[i])\n",
    "        writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_file = 'val_images.tfrecords'\n",
    "with tf.io.TFRecordWriter(val_file) as writer:\n",
    "    for i, filename in enumerate(X_val):\n",
    "        image_string = open(filename, 'rb').read()\n",
    "        tf_example = image_example(image_string, y_val[i])\n",
    "        writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}