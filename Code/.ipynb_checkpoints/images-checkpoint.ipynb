{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hoQQiZDB6URn"
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # Colab only\n",
    "\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate the images\n",
    "visit the images in the path, where they are classified by the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/.DS_Store\n",
      "/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/down_up\n",
      "/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/up\n",
      "/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/down\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "data_root = pathlib.Path.home().joinpath('Documents/Unimelb/Dissertation/test_Data/train_img/')\n",
    "for item in data_root.iterdir():\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "all_image_paths = list(data_root.glob('*/*'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "image_count = len(all_image_paths)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/up/000012_20141231.png',\n",
       " '/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/down_up/000668_20071023.png',\n",
       " '/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/down/000582_20000901.png',\n",
       " '/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/up/000055_20150513.png',\n",
       " '/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/up/000592_20051229.png',\n",
       " '/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/down_up/002335_20140210.png',\n",
       " '/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/down_up/002120_20101029.png',\n",
       " '/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/down_up/000597_20010118.png',\n",
       " '/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/down/000630_20010525.png',\n",
       " '/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/down_up/000402_20101108.png']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_image_paths[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OaNOr-co3WKk"
   },
   "source": [
    "### List the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['down', 'down_up', 'up']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9l_JEBql2OzS"
   },
   "source": [
    "#### set index for the label (as dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'down': 0, 'down_up': 1, 'up': 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "label_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VkXsHg162T9F"
   },
   "source": [
    "#### Store all labels for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 labels indices:  [2, 1, 0, 2, 2, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "all_image_labels =[]\n",
    "all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                    for path in all_image_paths]\n",
    "\n",
    "print(\"First 10 labels indices: \", all_image_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i5L09icm9iph"
   },
   "source": [
    "### Load and Normalize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbqqRUS79ooq"
   },
   "source": [
    "#### Take one image as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/cyril/Documents/Unimelb/Dissertation/test_Data/train_img/up/000012_20141231.png'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = all_image_paths[0]\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img_cv = cv2.imread(img_path)\n",
    "img_cv = img_cv[:, :, [2, 1, 0]]\n",
    "type(img_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCsAa4Psl4AQ"
   },
   "source": [
    "#### Design a function for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image):\n",
    "    image = cv2.imread(image)\n",
    "    image = cv2.resize(image, img_size)\n",
    "    image = image[:, :, [2, 1, 0]]\n",
    "    image = image.astype('float64')\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAEICAYAAABf40E1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAeIUlEQVR4nO3de5QU9ZXA8e/lOfLQgIMsAgNKCAlgBJk1agJHMxAQsot4xChG2OhZ0MiezPrYiIaHeDTGaHxE1xWPnAgqScQoHvGFQ1bWBAkQkZcgw0tgEBAREMMIM3f/qBqmp5me7umq6qqeup9z+kzXr35ddbt76vavXr+fqCrGmPhqFnYAxphwWRIwJuYsCRgTc5YEjIk5SwLGxJwlAWNizpKAMTFnScCkJCIqIl9PKpshIs+GFZPxnyUBY2LOkoDJmohcLCI7ReQOEflURLaJyDVhx2Uap0XYAZi8909AIdAVuAB4TURWqOrGcMMymbKWgPHDVFWtVNV3gIXAlWEHZDJnScA0pApomVTWEjiWMH1AVY8kTG8Hzgw6MOMfSwKmIR8DPZPKzsLZ0Gt0EJG2CdNFQEXAcRkfWRIwDfkD8AsR6SYizURkKPAvwPykeneJSCsRGQz8EHgh14Ga7NmBQdOQme7jXaADsBm4RlXXJtT5BDiA8+v/JXCDqm7IdaAme2KdiphsicjFwLOq2i3sWEz2bHfAmJizJGBMzAWWBERkhIhsFJFyEbk9qPWY8Kjq/9quQP4L5JiAiDQHPgKGATuB5cDVqrre95UZYzwJ6uzA+UC5qm4BEJHfA6OBepNAYWGh9uzZM6BQjDEAK1eu/FRVOyWXB5UEugI7EqZ3At9JrCAiE4GJAEVFRaxYsSKgUIwxACKyvb7y0A4MquosVS1W1eJOnU5KTsaYHAkqCewCuidMd3PLjDERE1QSWA70FpGzRKQVcBXwSkDrMsZ4EMgxAVU9LiKTgTeB5sBsVV0XxLqMMd4Edu+Aqr4GvBbU8o0x/rArBo2JOUsCxuSRO8ru4I6yO3xdpt1KbEweubfkXt+XaS0BY2LOkoAxMWdJwJiYsyRgTMxZEjAm5iwJGBNzlgSMiTlLAsbEnCUBY2LOkoAxMWdJwJiYsyRgTMxlnQREpLuI/FlE1ovIOhH5mVs+Q0R2icgq9zHSv3CNMX7zchfhceAWVf27iLQHVorIInfeQ6r6gPfwjDFByzoJqOpuYLf7/LCIfIjT1bgxJo/4ckxARHoCA4FlbtFkEVktIrNFpEOK10wUkRUismLfvn1+hGGMyYLnJCAi7YAXgVJVPQQ8AfQCBuC0FB6s73U27oAx0eApCYhIS5wE8Jyq/glAVfeoapWqVgNP4QxJZoyJKC9nBwR4GvhQVX+TUN4lodoYYG324Rljgubl7MB3gWuBNSKyyi27A7haRAYACmwDJnmK0BgTKC9nB94FpJ5ZNtaAMXnErhg0JuYsCRgTc5YEjIk5SwLGxJwlAWNizpKAMTFnScCYmLMkYEzMWRIwJuYsCRgTc5YEjIk5SwLGxJwlAWNizpKAMTFnScCYmPPSqQgAIrINOAxUAcdVtVhEOgJ/AHridCxypaoe8LouY4z//GoJXKKqA1S12J2+HShT1d5AmTttjImgoHYHRgPPuM+fAS4LaD3GGI/8SAIKvCUiK0VkolvW2R2cBOAToHPyi2zcAWOiwfMxAeB7qrpLRM4AFonIhsSZqqoioskvUtVZwCyA4uLik+YbY3LDc0tAVXe5f/cCL+GMM7Cnputx9+9er+sxJrbGjAl08V4HH2nrDkaKiLQFfoAzzsArwAS32gRgQUPLUbWGgDEpvfxyoIv3ujvQGXjJGYeEFsDzqvqGiCwH/igi1wPbgSsbWoj7emNMCDwlAVXdApxbT/l+oMTLso0xuWFXDBoTc5YEjIk5SwLGxJwlAWNizpKAMTFnScCYmLMkYIzPNh/YHHYIjWJJwBifPbbssbBDaBRLAsb4TE++Xy7SLAkY47f8ygGWBIyJO0sCxvgtz+6HsyRgjFdPPll32sPuQOXxSobNHcb4l8Z7i6kRLAkY49Vf/lJ32kNL4Hj1cd7e8jZzV8/1FlMjWBIwJmzz5p14qiEcVcw6CYhIHxFZlfA4JCKlIjJDRHYllI/0M2BjIq8x2/GXX8KyZTB/PgDtWrXjjR+/gU5PWEjAPW9l3amIqm4EBgCISHNgF04fgz8BHlLVBzJd1ldffZVtGMaEq6ZXrLlzT2ysiT1lyV21z+ts2DU+/RQeecR5hNTNnl+7AyXAZlXdns2LW7Vq5VMYxoRL7hIefu/hOht/1PmVBK4C5iVMTxaR1SIyW0Q6+LQOY0wAPCcBEWkF/Cvwglv0BNALZ1dhN/BgitfZ4CMmnh5/vPZ5URE8/3xouwLgT0vgUuDvqroHQFX3qGqVqlYDT+GMQ3ASVZ2lqsWqWtypUycfwjDGgy+/9GUxU4dM5Ttdv8PUIVN9WV4u+DEC0dUk7AqISJeEIcjG4IxDYEy0HTkCbdp4XszMS2ZyqPIQMy+ZmfUyBnUZ5DmOxvA8+AgwDPhTQvH9IrJGRFYDlwD/6WUdxjQpq1fDLbdAu3a1ZWPH1qlS2KYwpyF5HXfgCHB6Utm1niIyJmyVldC69YnJpTuWcmH3CzN+eddTu6aeWV3tLL+ysrashR8N8uzZFYPGJNu2re50I8/23XbRbb6FkgvhpiBj8oGfB+579ICf/ASGDfNxod5YS8CYdPy87qdDBxg0CK6+2seFemMtAWMCVHRaEQePHuS0gtPCDiUlawkYk07y7sDChRm/dHvpdm656Ba2lyZcUd+7tz9x+cRaAsYkqrn5p7AQaq5k9bg7cNKFQz/4gbcF+sxaAsakk2cdhzaWtQSMaUDN3YDNpBlV06pCjiYY1hIwJuYsCRgTc5YEjIk5OyZgTEGBcz9/4vX8DdWtroZmzeDo0eBjy4FItASOHTsWdggmziorIdN+Lisr4dix2oShCtdeG2qnIF5FIgm0bNky7BCMyd6cOWFH4IntDhiTqKICNm9OfVVfRQW8/TYMHZrbuAJkScCYRF26wKFD0Lkz4HQTvnTnUi7sdmHt/I4dnb9NREa7A26vwXtFZG1CWUcRWSQim9y/HdxyEZFHRaTc7XH4vKCCNyYXOrVJ6gOzawOdhuShTI8J/A4YkVR2O1Cmqr2BMncanI5He7uPiTi9DxuTP/r0qTP59Y5frzt/wIAcBhO8jJKAqi4BPksqHg084z5/BrgsoXyOOt4DviYiTaftZEwT4+XsQOeEXoU/ATq7z7sCOxLq7XTL6rBxB4yJBl9OEaqq0sh7rWzcAWOiwUsS2FPTzHf/7nXLdwHdE+p1c8uMMRHkJQm8Akxwn08AFiSUj3fPElwAHEzYbTDGRExG1wmIyDzgYqBQRHYC04H7gD+KyPXAduBKt/prwEigHPgSZ6hyY0xEZZQEVDVV16gl9dRV4CYvQZmYKSmBsrKUsz8++DFFpxXlMKB4icS9A8aY8FgSMBlZtmtZ7la2dWvu1mXs3gGTmd2Hc3Rst107Z4RgAFWKHi5ix0HnshOdnr+360aZtQRM/ZYsCTsCkyOWBEykia9jgJn6WBIwJubsmIAJV82IPyJOF11ffAGrVp24U2976XY7RRgwSwImrZoBOPbetvfke+uzdKjyEKe2PjWjupYAghWJ3YGqqqY5skteOXQop6u7/pXrc7q+OkRqWyAmGkmgefPmwa/kueeCX0c+25Fw9/dtt8ETT5zoQVenKy/96KU6rYDZ789u3PInTTrxVO4S5q+ff6KFcZIzz2xwUV9VZdgzcKZ+/WuYMcPfZeaR+OwOLFwI11wTdhT54YEHnL/PPefPL+ZFF8GWLbBmDfz1r+nrn3FGg7OPVR2jVfNW3uOqceutTjfiMRWfJGB8U/ML/t2i79Ln9D5pagNLlzp/9+w5eV6zHDRGq6vTryvG3d5HYncgCGv2rmlwfvln5TmKxCTT6coVfa9wrgCsqqp9ZCtpH1/ukrq7Gs2bOw9Tr/xOAr16pZx161u3NvjSh9972O9oomXgwMzqzZnjbED9+9eWTZkCP/5xJA+eDXxyIO1+2S718YRMTJkCt9+evl5MNNndgYauNHtn+zu8uulVtj2/jVfHvZrDqCKovg393nudy4YjmASy8mrSd3zvvbW7CCZ9SyDFmAO/FpEN7rgCL4nI19zyniLyDxFZ5T7+J8jg6ygtdQaLBO5ecjdvbn4z5a9FxeEKtn++nYWbFuYsvCiorMpgwM3G8HA/zwtjX/AvjnRGjXIepl6Z7A78jpPHHFgE9FfVbwMfAVMS5m1W1QHu4wZ/wqzH+PHOEeea00kPP1w7SmzyP+fjj8O8eU3nly2dyZOdq+6S3299G22qgTSHDKkzedk3Lzu5TkQ/Tp2udsdhI6RNAvWNOaCqb6nqcXfyPZzORE1ETfvzNOQuoeCegtrC3T7cGpy4nX3wQd15U6Zg8oMfBwavA15PmD5LRN4XkXdEZHCqFwU67kBEf6E8KShIXyfXEj/nRYsSygXuu8+5NgOc1sbEib4M3/3+pPc5POVw3V961bweGjxsnpKAiNwJHAdqLsfbDRSp6kDgZuB5Ean3AnEbd8Cbc544p27B4JT5tsnx5fbiXFyfkCey/iRE5N+AHwLXuJ2LoqqVqrrffb4S2Ax8w4c4GycGPwpbP0/qgmv79nACAWfX4tAh+Mrny3lTaNuqbU7WExdZJQERGQH8F/CvqvplQnknEWnuPj8bZ1DSLX4E2hjf6vQtOrftzBV9r3AKbroJrr46f5uM//zPUFnp9MoLjHh2BEe+OlJ79mPZMvjHP2D+/HDiO/NMuPtuWLnSmVZ1jgkkHpEfNCic2ExamZwinAcsBfqIyE53nIHHgPbAoqRTgUOA1SKyCpgP3KCqyQOZBu6Kvldw7j+dm9vTUDmkyU2dRx6BTz+FsWPrrT/zkpnodOXoL446Z1FEas+qjB/vbLSffhps0BMnBrt8k7W0FwulGHPg6RR1XwRe9BpUfWp+9fqd0Y+1N65NUztmnn8e/vIXb7sEp5+ecdXWzVtTpVW1++aqzk1HF15YW8ku080b+Xd0JMMWfVPum+7NH79J21ZtTz5CXuOxx5yeeZJ3f3zaGzr6i6M8+cMn+cbpDRzuuftuf1ZmApc3SWDqkKkUtCjghmL3+qM5c+Dss6Giot76484Zl3JZ/Tv1Z+qQqUwdMjWIUHMjeYNOvjCovua3j3nxuoHX1S24teF7NUx05c29AzMvmclv//ZbJp8/OaP6488dX7cg4YaRczqfwzmdk06x5bvkX/0bb6ynDjBmDHzrW/BZzg/VmIjKmyRQr82bM6/77W8HF0cUbNiQtkrrFq2hRw/n4ccVg6ZJiMTuQHVTuaMrxa5JIJKb9m3aNO71Me5Ew9QViSTQLAJXb/1t19+8L+Shh7wvI0NfTPnC2wIKC/0JxOS98Le+Rjjw8wOBLfvVjyLWr8BPfxp2BCYm8vuYQJT06AEHDsDQoTB8uLdlDR7s9Mun6vT6a0yA8qolEJQ3N7/J3UvuRu4SKo9n2fHGxx/D4cPO5bteVVQ4fe4FfRWfMVgSyA/Ll0Pr1lBWFnYkpgmyJJAsrAsN77mn4fkPN/GOUU1oLAkkq7nmJpMRi375S//WO29ew/NvCK6nNhNvlgRSSertaM4Hc2onVOHIEef++Wz7y0/sw69DB1i3rs5QXcbkip0dyMbBg86GC3DJJc4GPXw4bNyYdggtY6LGWgLJBNi1C15/HaZNg8OH2XJgCxNenoDcJazbu67+173xBjz1lDPuXtp1CPzf/8Edd9Q/v7QU2reHH/0o67dhTKayHXdghojsShhfYGTCvCkiUi4iG0XE4wnzECjOKbq33nJuh/2iEVfmDR3ayHW5ByAOHIB+/eDJJ53p//gPaNcOrriiccszJgvZjjsA8FDC+AKvAYhIX+AqoJ/7mv+u6W4sb0SlG4Jt28KOwMREVuMONGA08Hu3w9GtQDlwvof4cmJ4r+FMHTIVna60bt4a2raF7t2huDjYG20S+wBYm9RbUisfh942pgFejglMdochmy0i7lEyugI7EursdMtOEui4A1m4sHtC11h9+8LNNzsX6diNNqaJyzYJPAH0AgbgjDXwYGMXELVxBy79+qV1C0pLwwnEmBzLKgmo6h5VrVLVauApapv8u4DuCVW7uWV5rei0Ih699FEqbq6gT2EfOPVU5+DhlClwwQWZLeS669LXMSYE2Y470CVhcgxQs0P7CnCViLQWkbNwxh3w4Ub9cLVo1oJup3ajS/sutGjWwhm9pksXZ4jrFPvucpcw+/3ZtQUHEm6DPvtsZ1ixjh0DjtyY9NJeLOSOO3AxUCgiO4HpwMUiMgDnhNo2YBKAqq4TkT8C63GGJ7tJVbO8pC5axnxzTPYvnjsXduxwrgrs18/pFu2ee6xzThMJvo474Na/B0hzN0zMjHc7PX39dScJANx5Z3jxGJPArhg0JuYikQQ0X8cINKYJiEQSkOSBM4wxOROJJGCMCY8lAWNizvoTCEjKwUKNiRhrCRgTc5YEjIk5SwLGxJwlAWNizpKAMTFnScCYmLMkYEzMWRIwJuYsCRgTc5YEjIm5bAcf+UPCwCPbRGSVW95TRP6RMO9/ggzeGONdJvcO/A54DDgxIqeqnhgfS0QeBA4m1N+sqgP8CtAYE6xMuhdbIiI965snTkcAVwLf9zcsY0yueD0mMBjYo6qbEsrOEpH3ReQdERmc6oVRG3zEmLjymgSuBuYlTO8GilR1IHAz8LyInFrfC6M2+IgxcZV1EhCRFsDlwB9qytwxCPe7z1cCm4FveA3SGBMcL52KDAU2qOrOmgIR6QR8pqpVInI2zuAjW9ItaN26dfTt29dDKMaYbGU1+IiqPo0zBPm8pOpDgJkicgyoBm5Q1bQjGvfr148VK1Y0NnZjTCOk6tA328FHUNV/q6fsReDFRsZmTKjGu4PDdOnShV/96lchR5N7dsWgib3L//pX5qxfz4IFC8IOJRSWBIyJOUsCxsScJQFjYs6SgDExZ0nAmJizJGBMzEUiCRw7dizsEIyJrUgkgZYtW4YdgjFoTMeMjEQSMMaEx5KAMa5U19Y3dZYEjHGpKtdffz2TzziDOPVxYUnAmCSPFRVlXLesrIxx48Yxbty4ACMKlpf+BIyJvfLycp7/6CN6rV2bvnKWevTowfbt2wNbfl4ngYqKCo4fP06bNm0oLCwMO5wm4/PPP+fQoUMAFDXiV9EE4z8DPmuRybgD3UXkzyKyXkTWicjP3PKOIrJIRDa5fzu45SIij4pIuYisFpHzggp+8ODBFF1+OTfeeCMA8+bNY/HixUGtLjbuv/9+ii6/nLN69Ag7FAMQdhIAjgO3qGpf4ALgJhHpC9wOlKlqb6DMnQa4FKdbsd7AROAJ36NO4eoHH+See+7J1eqMyY2Az1qkTQKqultV/+4+Pwx8CHQFRgPPuNWeAS5zn48G5qjjPeBrItLF98hNzjzwwAP0ndqXFm3zeu8xLTtFmAF3EJKBwDKgs6rudmd9AnR2n3cFdiS8bKdblrwsG3cgj7Tp3gZp1rQ3ErtiMA0RaYfTf2Cpqh5KnKfOp9eoTzDX4w6MGzeOEaedZge6MhDXjSGyInBMABFpiZMAnlPVP7nFe2qa+e7fvW75LqB7wsu7uWWhe6N379g2+Rojrp9RZN932McE3PEGnwY+VNXfJMx6BZjgPp8ALEgoH++eJbgAOJiw2xC6fP2VW9ynD4v79GHatGkZ1Z84cSIlJSX8/Oc/T1v3oYceoqSkhNGjRwP5+xlFwTvvvENJSQklJSVhh5KxTFoC3wWuBb6fMOT4SOA+YJiIbMIZiOQ+t/5rOAOOlANPAT/1P+zs1WT70tJSCgoKOP3000OOKDPfb9+e77dvn3H95cuXU3bwIKtWrUpbd8OGDZQdPMiSJUu8hJiVyspKCgoKKCgoYNGiRTlffzq33XYbg/57EM2bNwec06c18dZn3759HPzRQd7b/F5W6zty5EiDyw9CJmcH3lVVUdVvq+oA9/Gaqu5X1RJV7a2qQ2sGGXHPCtykqr1U9RxV9W1UkQ4dOtB5aGcmTZqUtu7w4cMpnlXMwIEDk98PAMePH6f/o/2prKz0K7w6Nm7cSPGsYjZu3BjI8oOU62bx0f79Odq/P9XV1TlZ35JvfhOKi7nooosyqi8taj+PqqoqjvbvzynHjwcVHv0f7U/HoR0DW36yvLt3oPuV3dNXIvU/cqryadOm0WtSL3pN6pV1bH4aO3YsY8eOZeHChZ6WE8QGvXjx4hPxhaFm3fPnzw9l/Y2xdu1a759VwLtnTfbEb6r92ob2dzsM6hBUOI32wtatADy8aVOamg2reb9XXnkl7777LhUVFZ5j27ZtG1uHbWXdtHWel5WNrcOcz+bDDz/MqP7/9ulDn4IC/r17d1599dWMXuNX8ty7dy9bh21l0yOZfY/1/n+GfWDQ5IeioiIoLk55N9v+/fs5c8aZOY4qGjq1aEGXRvZelauDox9//DEUFzP5jDOAcM5QxC4JBPUh79u3j7lz5zJ37lyOHj0ayDoStWvXjsILC5k8eTLg7/uyswPhnS4M47OPXRII6kMuLy/n2kce4dpHHuHw4cMN1q2urmbSpElMmjSJNWvWZL3Onj/peeJ5lDfcioqKE+83k6tDZ/XsyayePZk3L3nQ6/y3Y8eOE59FVMQuCUTlgpAnV67kyZUrneagDxrzvm6++Wb69+/PiBEjfFl3OgcOHDjxftMlSICJhYVMTLg1vN+MfvSb0Y/HH388yDDrCCqp7t+/3/kcUhzUtN2BJmrfvn1QXAzFxSxdurT+Su78uXPnBh7Pjh07WFtQwKYUBx0b+4/48ssv06FFC1o2C+bf6ZQzT+GUM09JOb9y0CAoLqa0tBSAc399LsWzik8MOZ6NOO0ONNmzA6m+xEw/5K1bt7J+/XoARo0axc6dO/nggw9OTO/du5fly5cDMHLkSB8i9ibV+8rVP/OBAQO4aMMGAD777LMTyW7UqFEn1T169ChlZWUADB06NCfxNVakdq/sFGF2vG4UCxYsoPTZZ52JUaNYvHgxjx591JlkFMuXL2fU9OkAVF96qfeAXdn+83lNen5au3Yto6ZP54fl5Yz6/POT5h84cIDpu5zPbig+JAFVEInMrp4X9b4HO0WYnShtFLkQdksgCprqdxu0JpsE4rZRxC3pGf802STg98aeq+QRhbjzLnE00cSeK002CWRz2XA2y/Ob3/Hl3QZtcq7JJoHG3kCU7fL85nd8TXX3J1ai0LNQPorbL2Pc3m8dTf09BpzIJQr/JMXFxbpihW/dDhhj6iEiK1W1OLm8ybYEjDGZiURLQET2AUeAT8OOxYNC8jt+yP/3kO/xQ7DvoYeqntS1dySSAICIrKivqZIv8j1+yP/3kO/xQzjvwXYHjIk5SwLGxFyUksCssAPwKN/jh/x/D/keP4TwHiJzTMAYE44otQSMMSGwJGBMzIWeBERkhIhsFJFyEbk97HgyJSLbRGSNOyzbCreso4gsEpFN7t/oDGQAiMhsEdkrImsTyuqN2R1L8lH3e1ktIueFF/mJWOuLf4aI7EoaIq9m3hQ3/o0iMjycqGuJSHcR+bOIrBeRdSLyM7c83O9AVUN7AM2BzcDZQCvgA6BvmDE1IvZtQGFS2f3A7e7z24FfhR1nUnxDgPOAteliBkYCrwMCXAAsi2j8M4Bb66nb1/1/ag2c5f6fNQ85/i7Aee7z9sBHbpyhfgdhtwTOB8pVdYuqfgX8HhgdckxejAaecZ8/A1wWYiwnUdUlwGdJxaliHg3MUcd7wNdqhqIPS4r4UxkN/F5VK1V1K84AuecHFlwGVHW3qv7dfX4Y+BDoSsjfQdhJoCuwI2F6p1uWDxR4S0RWishEt6yz1g7D/gnQOZzQGiVVzPn03Ux2m8uzE3bBIh2/iPQEBgLLCPk7CDsJ5LPvqep5wKXATSIyJHGmOu25vDr/mo8xA08AvYABwG7gwXDDSU9E2gEvAqWqeihxXhjfQdhJYBeQOMxwN7cs8lR1l/t3L/ASTlNzT01zzf27N7wIM5Yq5rz4blR1j6pWqWo18BS1Tf5Ixi8iLXESwHOq+ie3ONTvIOwksBzoLSJniUgr4CrglZBjSktE2opI+5rnwA+AtTixT3CrTQAWhBNho6SK+RVgvHuE+gLgYEKTNTKS9pHH4HwP4MR/lYi0FpGzgN7A33IdXyJxunl6GvhQVX+TMCvc7yDMo6UJR0A/wjl6e2fY8WQY89k4R54/ANbVxA2cDpQBm4C3gY5hx5oU9zycJvMxnP3L61PFjHNE+nH3e1kDFEc0/rlufKvdjaZLQv073fg3ApdGIP7v4TT1VwOr3MfIsL8Du2zYmJgLe3fAGBMySwLGxJwlAWNizpKAMTFnScCYmLMkYEzMWRIwJub+H4WHTqyRXqbvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = all_image_paths[0]\n",
    "label = all_image_labels[0]\n",
    "\n",
    "plt.imshow(load_and_preprocess_image(img_path))\n",
    "plt.title(label_names[label].title())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15866d0d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia = load_and_preprocess_image(all_image_paths[10])\n",
    "plt.imshow(ia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all images and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:55<00:00, 272.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "images = []\n",
    "for image_path in tqdm(all_image_paths):\n",
    "    processed_image = load_and_preprocess_image(image_path)\n",
    "    images.append(processed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images = np.asarray(images)\n",
    "type(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_image_labels = np.asarray(all_image_labels)\n",
    "from keras.utils import to_categorical\n",
    "all_image_labels = to_categorical(all_image_labels, num_classes=3)\n",
    "type(all_image_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(images, all_image_labels, test_size=0.2, random_state=6)\n",
    "# print(x_train.shape)\n",
    "# print(x_val.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Bulid the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# base_model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "# base_model = VGG19(include_top=False, input_shape=(224, 224, 3))\n",
    "# base_model = MobileNet(include_top=False, input_shape=(224, 224, 3))\n",
    "base_model = ResNet50(include_top=False, input_shape=(224, 224, 3))\n",
    "# base_model = InceptionV3(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_NUMS = 1024\n",
    "# 冻结训练的层数，根据模型的不同，层数也不一样，根据调试的结果，VGG19和VGG16c层比较符合理想的测试结果，本文采用VGG19做示例\n",
    "FREEZE_LAYERS = 160\n",
    "# 进行训练和测试的图片大小，VGG19推荐为224×244\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(FC_NUMS, activation='relu')(x)\n",
    "prediction = Dense(NUM_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            3075        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 25,688,963\n",
      "Trainable params: 2,101,251\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n",
      "layer nums: 178\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 构造完新的FC层，加入custom层\n",
    "model = Model(inputs=base_model.input, outputs=prediction)\n",
    "# 可观察模型结构\n",
    "model.summary()\n",
    "# 获取模型的层数\n",
    "print(\"layer nums:\", len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: False\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n",
      "layer.trainable: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 除了FC层，靠近FC层的一部分卷积层可参与参数训练，\n",
    "# 一般来说，模型结构已经标明一个卷积块包含的层数，\n",
    "# 在这里我们选择FREEZE_LAYERS为17，表示最后一个卷积块和FC层要参与参数训练\n",
    "\n",
    "\n",
    "\n",
    "for layer in model.layers[:FREEZE_LAYERS]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[FREEZE_LAYERS:]:\n",
    "    layer.trainable = True\n",
    "for layer in model.layers:\n",
    "    print(\"layer.trainable:\", layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 给出训练图片的生成器， 其中classes定义后，可让model按照这个顺序进行识别\n",
    "# train_datagen = ImageDataGenerator()\n",
    "# train_generator = train_datagen.flow_from_directory(directory=TRAIN_PATH,\n",
    "#                                                     target_size=(IMAGE_SIZE, IMAGE_SIZE), classes=label_names)\n",
    "# test_datagen = ImageDataGenerator()\n",
    "# test_generator = test_datagen.flow_from_directory(directory=TEST_PATH,\n",
    "#                                                   target_size=(IMAGE_SIZE, IMAGE_SIZE), classes=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 20\n",
    "learing_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "  if epoch < 10:\n",
    "    return 0.001\n",
    "  else:\n",
    "    return 0.001 * tf.math.exp(0.1 * (10 - epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "# 当验证集上的损失“val_loss”连续两个训练回合（epoch）都没有变化，则提前结束训练\n",
    "tf.keras.callbacks.EarlyStopping(patience=4, monitor='val_loss'),\n",
    "# 使用TensorBoard保存训练的记录，保存到“./logs”目录中\n",
    "tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "tf.keras.callbacks.LearningRateScheduler(scheduler)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                             featurewise_std_normalization=True,\n",
    "                             rotation_range=15,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-7b9eeb53e068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                    callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    531\u001b[0m                      'at same time.')\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m   \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m   \u001b[0;31m# Handle validation_split, we want to split the data and get the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 998\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    999\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'int'>\"})"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch_size,\n",
    "                    epochs=epochs, verbose=1,\n",
    "                    validation_data = (x_val, y_val),\n",
    "                   callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (224, 224, 3), y.shape = (12000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-92fb9b3728f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n\u001b[0m\u001b[1;32m      2\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                callbacks=callbacks)\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         )\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             dtype=dtype)\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m     78\u001b[0m                              \u001b[0;34m'should have the same length. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                              \u001b[0;34m'Found: x.shape = %s, y.shape = %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                              (np.asarray(x).shape, np.asarray(y).shape))\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             raise ValueError('`x` (images tensor) and `sample_weight` '\n",
      "\u001b[0;31mValueError\u001b[0m: `x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (224, 224, 3), y.shape = (12000,)"
     ]
    }
   ],
   "source": [
    "# history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "#                               steps_per_epoch=len(x_train) // batch_size,\n",
    "#                               epochs = epochs, verbose=1,\n",
    "#                               validation_data = (x_val, y_val),\n",
    "#                                callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 97s 32ms/sample - loss: 1.1352 - accuracy: 0.3263\n",
      "loss: 1.1352094589869182\n",
      "accuracy: 0.32633334398269653\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_val, y_val)\n",
    "print(\"loss: {}\".format(result[0]))\n",
    "print(\"accuracy: {}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "images.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitc3aff01e4887446cafe7684cf3736cfd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
